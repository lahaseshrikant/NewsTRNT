# ğŸ¤– Content Engine â€” NewsTRNT's AI-Powered Content Pipeline

> **Version 2.0.0** Â· FastAPI Â· Python 3.11 Â· Port 8000

The **Content Engine** is the brain of the NewsTRNT platform â€” a persistent FastAPI
microservice that handles news scraping, AI summarization, topic classification,
SEO optimization, market data collection, sentiment analysis, and automated delivery
to the admin-backend.

---

## ğŸš€ Quick Start

```bash
# 1. Create virtual environment
python -m venv venv
venv\Scripts\activate      # Windows
# source venv/bin/activate # macOS/Linux

# 2. Install dependencies
pip install -r requirements.txt

# 3. Copy environment config
copy .env.example .env     # Windows
# cp .env.example .env     # macOS/Linux
# â†’ Edit .env with your API keys (see Environment Variables below)

# 4. Run the server
python main.py
# Or with uvicorn directly:
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Visit http://localhost:8000/docs for Swagger UI.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Admin Frontend  â”‚â”€â”€â”€â”€â–¶â”‚    Admin Backend (5002)   â”‚â—„â”€â”€â”€â”€â”‚  User Backend   â”‚
â”‚   (3001)         â”‚     â”‚                          â”‚     â”‚   (5000)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚               â”‚
                     API proxy â”‚        ingest  â”‚
                               â–¼               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Content Engine (8000)   â”‚
                     â”‚                          â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                     â”‚  â”‚Scraping â”‚â†’â”‚ Dedup  â”‚  â”‚
                     â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚
                     â”‚       â”‚          â”‚       â”‚
                     â”‚       â–¼          â–¼       â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                     â”‚  â”‚   AI Processing     â”‚ â”‚
                     â”‚  â”‚ Summarizeâ”‚Classifyâ”‚  â”‚ â”‚
                     â”‚  â”‚ Sentimentâ”‚SEO     â”‚  â”‚ â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚           â”‚              â”‚
                     â”‚           â–¼              â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                     â”‚  â”‚ Delivery Service    â”‚â”€â”¼â”€â”€â–¶ Admin Backend
                     â”‚  â”‚ POST /articles/ingestâ”‚ â”‚     /api/articles/ingest
                     â”‚  â”‚ POST /market/ingest  â”‚ â”‚     /api/market/ingest
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                     â”‚                          â”‚
                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                     â”‚  â”‚ APScheduler         â”‚ â”‚
                     â”‚  â”‚  news: every 30min  â”‚ â”‚
                     â”‚  â”‚  market: every 15minâ”‚ â”‚
                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                â–¼                â–¼
        RSS Feeds         NewsAPI.org      TradingView
        (10+ sources)     (top headlines)  (indices)
```

### Key Design Decisions

- **No direct DB writes** â€” all persistence goes through admin-backend HTTP API
- **Pipeline orchestration** â€” scrape â†’ dedup â†’ AI enrich â†’ deliver stages
- **Dual auth** â€” API key for service-to-service, JWT proxy for admin-frontend
- **Graceful fallbacks** â€” every AI function degrades to heuristic if OpenAI is down
- **Run tracking** â€” every pipeline execution is logged with per-stage metrics

---

## ğŸ“¡ API Reference

Base URL: `http://localhost:8000/api/v1`

### Health & Status

| Method | Path | Auth | Description |
|--------|------|------|-------------|
| `GET` | `/health` | None | Basic health check |
| `GET` | `/health/status` | Key | Detailed service status, uptime, scheduler state |

### Pipeline

| Method | Path | Auth | Description |
|--------|------|------|-------------|
| `POST` | `/pipeline/trigger` | Key | Trigger pipeline run (`{ type: 'full'\|'news'\|'market' }`) |
| `GET` | `/pipeline/history` | Key | Recent pipeline runs (accepts `?limit=N`) |
| `GET` | `/pipeline/runs/{run_id}` | Key | Get specific run detail with stages |

### Scraping

| Method | Path | Auth | Description |
|--------|------|------|-------------|
| `GET` | `/scraping/sources` | Key | List all configured scraping sources |
| `POST` | `/scraping/rss` | Key | Trigger RSS feed scrape |
| `POST` | `/scraping/newsapi` | Key | Trigger NewsAPI fetch |
| `POST` | `/scraping/market` | Key | Trigger TradingView market scrape |

### AI Processing

| Method | Path | Auth | Description |
|--------|------|------|-------------|
| `GET` | `/ai/status` | Key | AI provider health & model info |
| `POST` | `/ai/summarize` | Key | Summarize article content |
| `POST` | `/ai/classify` | Key | Classify article into categories |
| `POST` | `/ai/sentiment` | Key | Analyze article sentiment |
| `POST` | `/ai/seo-optimize` | Key | Generate SEO metadata |
| `POST` | `/ai/process` | Key | Full AI pipeline (all of the above) |

### Scheduler

| Method | Path | Auth | Description |
|--------|------|------|-------------|
| `GET` | `/scheduler/status` | Key | Scheduler state, jobs list |
| `POST` | `/scheduler/jobs` | Key | Create a new scheduled job |
| `PATCH` | `/scheduler/jobs/{id}` | Key | Pause/resume/update job |
| `DELETE` | `/scheduler/jobs/{id}` | Key | Remove a scheduled job |

### Configuration

| Method | Path | Auth | Description |
|--------|------|------|-------------|
| `GET` | `/config` | Key | Current runtime configuration |
| `PATCH` | `/config` | Key | Update runtime settings |

---

## âš™ï¸ Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `ENGINE_PORT` | No | `8000` | Server port |
| `ENGINE_HOST` | No | `0.0.0.0` | Bind address |
| `ENGINE_API_KEY` | **Yes** | â€” | API key for incoming requests |
| `ENGINE_ENV` | No | `development` | Environment (development/production) |
| `ENGINE_LOG_LEVEL` | No | `INFO` | Log level (DEBUG/INFO/WARNING/ERROR) |
| `ENGINE_WORKERS` | No | `1` | Uvicorn worker count |
| `ADMIN_BACKEND_URL` | **Yes** | `http://localhost:5002` | Admin backend base URL |
| `CONTENT_ENGINE_API_KEY` | **Yes** | â€” | Shared key for article delivery auth |
| `MARKET_INGEST_API_KEY` | No | â€” | Shared key for market data delivery |
| `OPENAI_API_KEY` | **Yes** | â€” | OpenAI API key |
| `AI_MODEL` | No | `gpt-3.5-turbo` | OpenAI model to use |
| `AI_MAX_TOKENS` | No | `4096` | Max tokens per AI request |
| `AI_TEMPERATURE` | No | `0.3` | AI temperature (0-1) |
| `NEWS_API_KEY` | No | â€” | NewsAPI.org API key |
| `NEWS_INTERVAL_MINUTES` | No | `30` | Auto-scrape news interval |
| `MARKET_INTERVAL_MINUTES` | No | `15` | Auto-scrape market interval |
| `MAX_ARTICLES_PER_RUN` | No | `50` | Max articles per pipeline run |
| `ENABLE_SCHEDULER` | No | `true` | Enable automatic task scheduling |
| `DEFAULT_TIMEZONE` | No | `UTC` | Scheduler timezone |
| `REDIS_URL` | No | â€” | Redis URL (optional caching) |

---

## ğŸ“ Project Structure

```
content-engine/
â”œâ”€â”€ main.py                      # FastAPI app entry point + lifespan
â”œâ”€â”€ config.py                    # Pydantic-settings configuration
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ Dockerfile                   # Production container
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ README.md                    # This file
â”‚
â”œâ”€â”€ api/                         # Route handlers
â”‚   â”œâ”€â”€ health.py                # GET /health, /health/status
â”‚   â”œâ”€â”€ scraping.py              # Scraping trigger endpoints
â”‚   â”œâ”€â”€ ai_processing.py         # AI processing endpoints
â”‚   â”œâ”€â”€ scheduler_routes.py      # Scheduler management
â”‚   â”œâ”€â”€ pipeline_routes.py       # Pipeline trigger & history
â”‚   â””â”€â”€ config_routes.py         # Runtime config
â”‚
â”œâ”€â”€ core/                        # Business logic
â”‚   â”œâ”€â”€ pipeline.py              # PipelineOrchestrator (main orchestration)
â”‚   â”œâ”€â”€ delivery.py              # HTTP delivery to admin-backend
â”‚   â””â”€â”€ deduplication.py         # Article dedup (MD5 + file cache)
â”‚
â”œâ”€â”€ scraping/                    # Data collection
â”‚   â”œâ”€â”€ base.py                  # BaseScraper ABC + helpers
â”‚   â”œâ”€â”€ rss_scraper.py           # RSS feed aggregator (10+ sources)
â”‚   â”œâ”€â”€ newsapi_scraper.py       # NewsAPI.org client
â”‚   â””â”€â”€ tradingview_scraper.py   # TradingView market scraper
â”‚
â”œâ”€â”€ ai/                          # AI enrichment
â”‚   â”œâ”€â”€ provider.py              # Centralized OpenAI client
â”‚   â”œâ”€â”€ summarizer.py            # Article summarization
â”‚   â”œâ”€â”€ classifier.py            # Topic classification (12 categories)
â”‚   â”œâ”€â”€ seo_optimizer.py         # SEO analysis (zero API cost)
â”‚   â””â”€â”€ sentiment.py             # Sentiment analysis
â”‚
â”œâ”€â”€ scheduler/                   # Task scheduling
â”‚   â””â”€â”€ manager.py               # APScheduler wrapper + job CRUD
â”‚
â”œâ”€â”€ models/                      # Pydantic data models
â”‚   â”œâ”€â”€ article.py               # Article lifecycle models
â”‚   â”œâ”€â”€ market.py                # Market data models
â”‚   â”œâ”€â”€ pipeline.py              # Pipeline run tracking
â”‚   â””â”€â”€ responses.py             # Standard API responses
â”‚
â”œâ”€â”€ middleware/                   # Request processing
â”‚   â”œâ”€â”€ auth.py                  # API key verification
â”‚   â”œâ”€â”€ logging_mw.py            # Request/response logging
â”‚   â””â”€â”€ rate_limit.py            # Token-bucket rate limiter
â”‚
â”œâ”€â”€ utils/                       # Shared utilities
â”‚   â”œâ”€â”€ http_client.py           # Async HTTP client
â”‚   â””â”€â”€ text_processing.py       # Text cleaning helpers
â”‚
â””â”€â”€ data/                        # Runtime data (gitignored)
    â””â”€â”€ seen_hashes.json         # Deduplication cache
```

---

## ğŸ”„ Pipeline Flow

```
1. SCRAPE     RSS Feeds + NewsAPI â†’ raw articles
                   â†“
2. DEDUP      MD5(title) â†’ filter seen articles
                   â†“
3. AI ENRICH  Summarize + Classify + Sentiment + SEO
                   â†“
4. DELIVER    POST articles to admin-backend /api/articles/ingest
                   â†“
5. TRACK      Log run in ScraperRun table via admin-backend
```

Each stage produces a `StageResult` with:
- `status` (completed / failed / skipped)
- `duration_ms`
- `items_in` / `items_out`
- `error` (if any)

The full `PipelineRun` is kept in memory (last 200 runs) and available
via `GET /api/v1/pipeline/history`.

---

## ğŸ³ Docker

```bash
# Build
docker build -t content-engine .

# Run
docker run -d \
  --name content-engine \
  -p 8000:8000 \
  --env-file .env \
  content-engine
```

---

## ğŸ” Authentication

### Incoming Requests (to Content Engine)

All endpoints (except `/health`) require `X-API-Key` header matching `ENGINE_API_KEY`.

In development, if `ENGINE_API_KEY` is empty, auth is bypassed.

### Outgoing Requests (to Admin Backend)

The Content Engine sends `Authorization: Bearer <CONTENT_ENGINE_API_KEY>` when
delivering articles/market data to admin-backend.

Admin-backend accepts this key via its `CONTENT_ENGINE_API_KEY` env var.

---

## ğŸ“Š Admin Dashboard

The admin-frontend includes a full Content Engine management UI at `/content-engine`:

- **Dashboard** â€” service health, quick pipeline triggers, ingest stats
- **Pipeline Monitor** â€” run history with per-stage detail view
- **Scheduler** â€” view/pause/resume/delete scheduled jobs
- **Sources** â€” list RSS feeds, NewsAPI, market sources
- **AI Processing** â€” AI provider status, feature overview, test area

Access: Super Admin only (via admin-backend proxy at `/api/content-engine/*`).
